import pandas as pd
import numpy as np
import re
import nltk 
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.corpus import wordnet
import string
import pickle

lemmatizer = WordNetLemmatizer()
stopWordsLong = '''a<br />able<br />about<br />above<br />abst<br />accordance<br />according<br />accordingly<br />across<br />act<br />actually<br />added<br />adj<br />affected<br />affecting<br />affects<br />after<br />afterwards<br />again<br />against<br />ah<br />all<br />almost<br />alone<br />along<br />already<br />also<br />although<br />always<br />am<br />among<br />amongst<br />an<br />and<br />announce<br />another<br />any<br />anybody<br />anyhow<br />anymore<br />anyone<br />anything<br />anyway<br />anyways<br />anywhere<br />apparently<br />approximately<br />are<br />aren<br />arent<br />arise<br />around<br />as<br />aside<br />ask<br />asking<br />at<br />auth<br />available<br />away<br />awfully<br />b<br />back<br />be<br />became<br />because<br />become<br />becomes<br />becoming<br />been<br />before<br />beforehand<br />begin<br />beginning<br />beginnings<br />begins<br />behind<br />being<br />believe<br />below<br />beside<br />besides<br />between<br />beyond<br />biol<br />both<br />brief<br />briefly<br />but<br />by<br />c<br />ca<br />came<br />can<br />cannot<br />can't<br />cause<br />causes<br />certain<br />certainly<br />co<br />com<br />come<br />comes<br />contain<br />containing<br />contains<br />could<br />couldnt<br />d<br />date<br />did<br />didn't<br />different<br />do<br />does<br />doesn't<br />doing<br />done<br />don't<br />down<br />downwards<br />due<br />during<br />e<br />each<br />ed<br />edu<br />effect<br />eg<br />eight<br />eighty<br />either<br />else<br />elsewhere<br />end<br />ending<br />enough<br />especially<br />et<br />et-al<br />etc<br />even<br />ever<br />every<br />everybody<br />everyone<br />everything<br />everywhere<br />ex<br />except<br />f<br />far<br />few<br />ff<br />fifth<br />first<br />five<br />fix<br />followed<br />following<br />follows<br />for<br />former<br />formerly<br />forth<br />found<br />four<br />from<br />further<br />furthermore<br />g<br />gave<br />get<br />gets<br />getting<br />give<br />given<br />gives<br />giving<br />go<br />goes<br />gone<br />got<br />gotten<br />h<br />had<br />happens<br />hardly<br />has<br />hasn't<br />have<br />haven't<br />having<br />he<br />hed<br />hence<br />her<br />here<br />hereafter<br />hereby<br />herein<br />heres<br />hereupon<br />hers<br />herself<br />hes<br />hi<br />hid<br />him<br />himself<br />his<br />hither<br />home<br />how<br />howbeit<br />however<br />hundred<br />i<br />id<br />ie<br />if<br />i'll<br />im<br />immediate<br />immediately<br />importance<br />important<br />in<br />inc<br />indeed<br />index<br />information<br />instead<br />into<br />invention<br />inward<br />is<br />isn't<br />it<br />itd<br />it'll<br />its<br />itself<br />i've<br />j<br />just<br />k<br />keep</td>
<td valign="top">keeps<br />kept<br />kg<br />km<br />know<br />known<br />knows<br />l<br />largely<br />last<br />lately<br />later<br />latter<br />latterly<br />least<br />less<br />lest<br />let<br />lets<br />like<br />liked<br />likely<br />line<br />little<br />'ll<br />look<br />looking<br />looks<br />ltd<br />m<br />made<br />mainly<br />make<br />makes<br />many<br />may<br />maybe<br />me<br />mean<br />means<br />meantime<br />meanwhile<br />merely<br />mg<br />might<br />million<br />miss<br />ml<br />more<br />moreover<br />most<br />mostly<br />mr<br />mrs<br />much<br />mug<br />must<br />my<br />myself<br />n<br />na<br />name<br />namely<br />nay<br />nd<br />near<br />nearly<br />necessarily<br />necessary<br />need<br />needs<br />neither<br />never<br />nevertheless<br />new<br />next<br />nine<br />ninety<br />no<br />nobody<br />non<br />none<br />nonetheless<br />noone<br />nor<br />normally<br />nos<br />not<br />noted<br />nothing<br />now<br />nowhere<br />o<br />obtain<br />obtained<br />obviously<br />of<br />off<br />often<br />oh<br />ok<br />okay<br />old<br />omitted<br />on<br />once<br />one<br />ones<br />only<br />onto<br />or<br />ord<br />other<br />others<br />otherwise<br />ought<br />our<br />ours<br />ourselves<br />out<br />outside<br />over<br />overall<br />owing<br />own<br />p<br />page<br />pages<br />part<br />particular<br />particularly<br />past<br />per<br />perhaps<br />placed<br />please<br />plus<br />poorly<br />possible<br />possibly<br />potentially<br />pp<br />predominantly<br />present<br />previously<br />primarily<br />probably<br />promptly<br />proud<br />provides<br />put<br />q<br />que<br />quickly<br />quite<br />qv<br />r<br />ran<br />rather<br />rd<br />re<br />readily<br />really<br />recent<br />recently<br />ref<br />refs<br />regarding<br />regardless<br />regards<br />related<br />relatively<br />research<br />respectively<br />resulted<br />resulting<br />results<br />right<br />run<br />s<br />said<br />same<br />saw<br />say<br />saying<br />says<br />sec<br />section<br />see<br />seeing<br />seem<br />seemed<br />seeming<br />seems<br />seen<br />self<br />selves<br />sent<br />seven<br />several<br />shall<br />she<br />shed<br />she'll<br />shes<br />should<br />shouldn't<br />show<br />showed<br />shown<br />showns<br />shows<br />significant<br />significantly<br />similar<br />similarly<br />since<br />six<br />slightly<br />so<br />some<br />somebody<br />somehow<br />someone<br />somethan<br />something<br />sometime<br />sometimes<br />somewhat<br />somewhere<br />soon<br />sorry<br />specifically<br />specified<br />specify<br />specifying<br />still<br />stop<br />strongly<br />sub<br />substantially<br />successfully<br />such<br />sufficiently<br />suggest<br />sup<br />sure</td>
<td valign="top">t<br />take<br />taken<br />taking<br />tell<br />tends<br />th<br />than<br />thank<br />thanks<br />thanx<br />that<br />that'll<br />thats<br />that've<br />the<br />their<br />theirs<br />them<br />themselves<br />then<br />thence<br />there<br />thereafter<br />thereby<br />thered<br />therefore<br />therein<br />there'll<br />thereof<br />therere<br />theres<br />thereto<br />thereupon<br />there've<br />these<br />they<br />theyd<br />they'll<br />theyre<br />they've<br />think<br />this<br />those<br />thou<br />though<br />thoughh<br />thousand<br />throug<br />through<br />throughout<br />thru<br />thus<br />til<br />tip<br />to<br />together<br />too<br />took<br />toward<br />towards<br />tried<br />tries<br />truly<br />try<br />trying<br />ts<br />twice<br />two<br />u<br />un<br />under<br />unfortunately<br />unless<br />unlike<br />unlikely<br />until<br />unto<br />up<br />upon<br />ups<br />us<br />use<br />used<br />useful<br />usefully<br />usefulness<br />uses<br />using<br />usually<br />v<br />value<br />various<br />'ve<br />very<br />via<br />viz<br />vol<br />vols<br />vs<br />w<br />want<br />wants<br />was<br />wasnt<br />way<br />we<br />wed<br />welcome<br />we'll<br />went<br />were<br />werent<br />we've<br />what<br />whatever<br />what'll<br />whats<br />when<br />whence<br />whenever<br />where<br />whereafter<br />whereas<br />whereby<br />wherein<br />wheres<br />whereupon<br />wherever<br />whether<br />which<br />while<br />whim<br />whither<br />who<br />whod<br />whoever<br />whole<br />who'll<br />whom<br />whomever<br />whos<br />whose<br />why<br />widely<br />willing<br />wish<br />with<br />within<br />without<br />wont<br />words<br />world<br />would<br />wouldnt<br />www<br />x<br />y<br />yes<br />yet<br />you<br />youd<br />you'll<br />your<br />youre<br />yours<br />yourself<br />yourselves<br />you've<br />z<br />zero'''
stopWordsNltk = set(stopwords.words('english'))
stopWords = set(stopWordsLong.split('<br />')).union(stopWordsNltk)

def get_wordnet_pos(treebank_tag):
    if treebank_tag.startswith('J'):
        return wordnet.ADJ
    elif treebank_tag.startswith('V'):
        return wordnet.VERB
    elif treebank_tag.startswith('N'):
        return wordnet.NOUN
    elif treebank_tag.startswith('R'):
        return wordnet.ADV
    else:
        return ''

def lemmatize(word):
    try:
        if word[-1] == '.':
            return lemmatizer.lemmatize(word[:-1] ,get_wordnet_pos(nltk.pos_tag([word])[0][1]))
        else:
            return lemmatizer.lemmatize(word ,get_wordnet_pos(nltk.pos_tag([word])[0][1]))
    except (KeyError,IndexError):
        return word

def clean(data):
    tokens = nltk.word_tokenize(data.lower())
    tokens = [lemmatize(token) for token in tokens if token not in stopWords]
    return ' '.join(tokens)
